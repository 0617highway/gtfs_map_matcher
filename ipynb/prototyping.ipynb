{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import gtfstk as gt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapely.geometry as sg\n",
    "\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "OUT_DIR = Path('../output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_route_short_names_duplicated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frac_route_short_names_duplicated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_stop_time_dists_missing</td>\n",
       "      <td>340007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frac_stop_time_dists_missing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_direction_ids_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>frac_direction_ids_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_trips_missing_shapes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>frac_trips_missing_shapes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>frac_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num_first_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>frac_first_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>num_last_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>frac_last_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>assessment</td>\n",
       "      <td>probably a fixable feed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             indicator                    value\n",
       "0     num_route_short_names_duplicated                        0\n",
       "1    frac_route_short_names_duplicated                        0\n",
       "2          num_stop_time_dists_missing                   340007\n",
       "3         frac_stop_time_dists_missing                        1\n",
       "4            num_direction_ids_missing                        0\n",
       "5           frac_direction_ids_missing                        0\n",
       "6             num_trips_missing_shapes                        0\n",
       "7            frac_trips_missing_shapes                        0\n",
       "8          num_departure_times_missing                        0\n",
       "9         frac_departure_times_missing                        0\n",
       "10   num_first_departure_times_missing                        0\n",
       "11  frac_first_departure_times_missing                        0\n",
       "12    num_last_departure_times_missing                        0\n",
       "13   frac_last_departure_times_missing                        0\n",
       "14                          assessment  probably a fixable feed"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = DATA_DIR/'wellington_gtfs_20171016.zip'\n",
    "feed = gt.read_gtfs(path, dist_units='km')\n",
    "feed.assess_quality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes_g = feed.shapes_to_geojson()\n",
    "# path = Path('../wellington_shapes_20171016.geojson')\n",
    "# with path.open('w') as tgt:\n",
    "#     json.dump(shapes_g, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If no shapes, use stops only.\n",
    "If shapes, then add distances to stop times and to shapes\n",
    "\"\"\"\n",
    "trip_stats = feed.compute_trip_stats(compute_dist_from_shapes=True)\n",
    "feed = feed.append_dist_to_stop_times(trip_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine(xs, n):\n",
    "    \"\"\"\n",
    "    Given a strictly increasing NumPy array ``xs`` of at least two numbers\n",
    "    x_1 < x_2 < ... < x_r and an integer ``n`` >= 0, \n",
    "    insert into the list ``n`` more numbers between x_1 and x_r\n",
    "    in a spread-out way.\n",
    "    Return the resulting list as a NumPy array.\n",
    "    \"\"\"\n",
    "    while n > 0:\n",
    "        diffs = np.diff(xs)\n",
    "\n",
    "        # Get indices i, j of biggest diffs d_i > d_j.\n",
    "        # Use the method at https://stackoverflow.com/a/23734295 for speed.\n",
    "        try:\n",
    "            indices = np.argpartition(diffs, -2)[-2:]\n",
    "            i, j = indices[np.argsort(diffs[indices])[::-1]]\n",
    "            d_i, d_j = diffs[i], diffs[j]\n",
    "            \n",
    "            # Choose k => 1 least such that d_i/(k + 1) < d_j\n",
    "            # with the intent of inserting k evenly spaced points \n",
    "            # between x_i and x_{i+1}\n",
    "            k = int(max(1, np.ceil(d_i/d_j - 1)))\n",
    "\n",
    "            # Shrink k if necessary so as not to exceed number of remaining points\n",
    "            k = min(k, n)\n",
    "        except ValueError:\n",
    "            # Here xs has only two elements, hence diffs has only one element.\n",
    "            # Using try-except because faster than if-else.\n",
    "            i = 0\n",
    "            d_i = diffs[0]\n",
    "            k = n\n",
    "        \n",
    "        # Insert the k points, updating xs\n",
    "        xs = np.concatenate([\n",
    "          xs[:i + 1], \n",
    "          [xs[i] + s*d_i/(k + 1) for s in range(1, k + 1)], \n",
    "          xs[i + 1:]\n",
    "          ])\n",
    "        \n",
    "        # Update n\n",
    "        n -= k\n",
    "        \n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test refine() some\n",
    "\n",
    "xs = np.array([0, 3/4, 1])\n",
    "assert np.array_equal(refine(xs, 0), xs)\n",
    "assert np.array_equal(refine(xs, 1), np.array([0, 3/8, 3/4, 1]))\n",
    "assert np.array_equal(refine(xs, 2), np.array([0, 1/4, 1/2, 3/4, 1]))\n",
    "assert np.array_equal(refine(xs, 3), np.array([0, 1/4, 1/2, 3/4, 7/8, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_patterns(feed, trip_ids=None, sep='-'):\n",
    "    \"\"\"\n",
    "    Return the DataFrame ``feed.trips`` with the additional column\n",
    "    \n",
    "    - ``'stop_pattern'``: string; the stop IDs along the \n",
    "      trip joined by the separator ``sep``\n",
    "      \n",
    "    If a list of trip IDs is also given, then restrict the output\n",
    "    to those trip IDs.\n",
    "    \"\"\"\n",
    "    st = feed.stop_times.copy()\n",
    "    if trip_ids is not None:\n",
    "        # Filter to given trip IDs\n",
    "        st = st[st['trip_id'].isin(trip_ids)].copy()\n",
    "            \n",
    "    def get_pattern(group):\n",
    "        return group.stop_id.str.cat(sep=sep)\n",
    "        \n",
    "    f = st.groupby('trip_id').apply(get_pattern).reset_index().rename(\n",
    "      columns={0: 'stop_pattern'})\n",
    "    return feed.trips.merge(f)\n",
    "    \n",
    "def build_sample_points_by_trip(feed, trip_ids=None, max_sample_points=100):\n",
    "    \"\"\"\n",
    "    Given a GTFS feed (GTFSTK Feed instance), \n",
    "    preferably with a ``feed.stop_times.shape_dist_traveled`` column, \n",
    "    return a dictionary of the form \n",
    "    \n",
    "    trip ID -> list of (longitude, latitude) sample points along trip.\n",
    "    \n",
    "    Each sample point list comprises the k stop points of the trip\n",
    "    along with ``max_sample_points - k`` additional points somewhat evenly \n",
    "    sampled from the trip shape, all in the order of the trip's travel.\n",
    "    If k >= ``max_sample_points`` or if the trip has no shape ID or\n",
    "    if the trip has fewer than two ``shape_dist_traveled`` values, then\n",
    "    only include the k stops of the trip.\n",
    "    \"\"\"\n",
    "    t = feed.trips\n",
    "    \n",
    "    if trip_ids is not None:\n",
    "        # Filter trips to given trip IDs\n",
    "        t = t[t['trip_id'].isin(trip_ids)].copy()\n",
    "    \n",
    "    # Append stop patterns to trips for later\n",
    "    t = get_stop_patterns(feed, t.trip_id)\n",
    "    \n",
    "    # Get shape geometries\n",
    "    geom_by_shape = feed.build_geometry_by_shape(shape_ids=t.shape_id) or {}\n",
    "    \n",
    "    # Get stops times for the given trips\n",
    "    st = feed.stop_times\n",
    "    st = st[st['trip_id'].isin(t.trip_id)].sort_values(\n",
    "      ['trip_id', 'stop_sequence']).merge(t[['trip_id', 'stop_pattern']])\n",
    "\n",
    "    # Append null dists for later\n",
    "    if not 'shape_dist_traveled' in st:\n",
    "        st['shape_dist_traveled'] = np.nan\n",
    "    \n",
    "    # Join in stop locations\n",
    "    st = st.merge(t).merge(feed.stops)\n",
    "    \n",
    "    # Build dictionary (shape ID, stop pattern) -> list of (lon, lat) sample points,\n",
    "    # instead of trip ID -> list of (lon, lat) sample points, because the former\n",
    "    # avoids repeating computations.\n",
    "    n = max_sample_points\n",
    "    points_by_ssp = {}    \n",
    "    for (shape_id, stop_pattern), group in st.groupby(['shape_id', 'stop_pattern']):\n",
    "        if (shape_id, stop_pattern) in points_by_ssp:\n",
    "            # Already computed\n",
    "            continue\n",
    "            \n",
    "        k = group.shape[0]  # Number of stops along trip            \n",
    "        if k >= n or shape_id not in geom_by_shape\\\n",
    "          or group.shape_dist_traveled.count() < 2:\n",
    "            # Use stop points only\n",
    "            points = group[['stop_lon', 'stop_lat']].values.tolist()\n",
    "        else:\n",
    "            # Start with stop points, and mark their distances for later sorting.\n",
    "            # Scale distances to interval [0, 1] to avoid changing coordinate systems.\n",
    "            group['shape_dist_traveled'] /= group['shape_dist_traveled'].max()\n",
    "            stop_points = group[['stop_lon', 'stop_lat', 'shape_dist_traveled']].values\n",
    "            dists = group['shape_dist_traveled'].values\n",
    "            \n",
    "            # Get n - k nicely spaced points from trip shape.\n",
    "            new_dists = np.setdiff1d(refine(dists, n - k), dists)   \n",
    "            geom = geom_by_shape[shape_id]\n",
    "            shape_points = [\n",
    "              list(geom.interpolate(d, normalized=True).coords[0]) + [d]\n",
    "              for d in new_dists]\n",
    "            \n",
    "            # Combine with stop points and sort\n",
    "            points = sorted(np.concatenate([stop_points, shape_points]).tolist(), \n",
    "              key=lambda x: x[2])\n",
    "            \n",
    "            # Remove distance markers\n",
    "            points = [x[:2] for x in points]\n",
    "            \n",
    "        points_by_ssp[(shape_id, stop_pattern)] = points\n",
    "\n",
    "    # Build final dict trip ID -> list of (lon, lat) sample points\n",
    "    return {t: points_by_ssp[(s, sp)] \n",
    "      for t, s, sp in t[['trip_id', 'shape_id', 'stop_pattern']].values}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 524 ms, sys: 0 ns, total: 524 ms\n",
      "Wall time: 520 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araichev/.virtualenvs/snap_bus_routes/lib/python3.5/site-packages/ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 140 ms, total: 12.1 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "t = feed.trips.sample(frac=0.1)\n",
    "%time tp1 = build_sample_points_by_trip(feed, t.trip_id, 1)\n",
    "%time tp2 = build_sample_points_by_trip(feed, t.trip_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110__0__2149__VLYF__715__1__715__1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tp2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-16b63cdf0b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLineString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLineString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tp2' is not defined"
     ]
    }
   ],
   "source": [
    "tid = t.trip_id.iat[2]\n",
    "print(tid)\n",
    "l1 = sg.LineString(tp1[tid])\n",
    "l2 = sg.LineString(tp2[tid])\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
