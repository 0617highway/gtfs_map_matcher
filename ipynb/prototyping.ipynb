{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import gtfstk as gt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapely.geometry as sg\n",
    "\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "OUT_DIR = Path('../output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_route_short_names_duplicated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frac_route_short_names_duplicated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_stop_time_dists_missing</td>\n",
       "      <td>340007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frac_stop_time_dists_missing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_direction_ids_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>frac_direction_ids_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_trips_missing_shapes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>frac_trips_missing_shapes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>frac_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num_first_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>frac_first_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>num_last_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>frac_last_departure_times_missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>assessment</td>\n",
       "      <td>probably a fixable feed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             indicator                    value\n",
       "0     num_route_short_names_duplicated                        0\n",
       "1    frac_route_short_names_duplicated                        0\n",
       "2          num_stop_time_dists_missing                   340007\n",
       "3         frac_stop_time_dists_missing                        1\n",
       "4            num_direction_ids_missing                        0\n",
       "5           frac_direction_ids_missing                        0\n",
       "6             num_trips_missing_shapes                        0\n",
       "7            frac_trips_missing_shapes                        0\n",
       "8          num_departure_times_missing                        0\n",
       "9         frac_departure_times_missing                        0\n",
       "10   num_first_departure_times_missing                        0\n",
       "11  frac_first_departure_times_missing                        0\n",
       "12    num_last_departure_times_missing                        0\n",
       "13   frac_last_departure_times_missing                        0\n",
       "14                          assessment  probably a fixable feed"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = DATA_DIR/'wellington_gtfs_20171016.zip'\n",
    "feed = gt.read_gtfs(path, dist_units='km')\n",
    "feed.assess_quality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes_g = feed.shapes_to_geojson()\n",
    "# path = Path('../wellington_shapes_20171016.geojson')\n",
    "# with path.open('w') as tgt:\n",
    "#     json.dump(shapes_g, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If no shapes, use stops only.\n",
    "If shapes, then add distances to stop times and to shapes\n",
    "\"\"\"\n",
    "trip_stats = feed.compute_trip_stats(compute_dist_from_shapes=True)\n",
    "feed = feed.append_dist_to_stop_times(trip_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine(xs, n):\n",
    "    \"\"\"\n",
    "    Given a strictly increasing NumPy array ``xs`` of at least two numbers\n",
    "    x_1 < x_2 < ... < x_r and a nonnegative integer ``n``, \n",
    "    insert into the list ``n`` more numbers between x_1 and x_r\n",
    "    in a spread-out way.\n",
    "    Return the resulting list as a NumPy array.\n",
    "    \"\"\"\n",
    "    while n > 0:\n",
    "        diffs = np.diff(xs)\n",
    "\n",
    "        # Get indices i, j of biggest diffs d_i > d_j.\n",
    "        # Use the method at https://stackoverflow.com/a/23734295 for speed.\n",
    "        try:\n",
    "            indices = np.argpartition(diffs, -2)[-2:]\n",
    "            i, j = indices[np.argsort(diffs[indices])[::-1]]\n",
    "            d_i, d_j = diffs[i], diffs[j]\n",
    "            \n",
    "            # Choose k => 1 least such that d_i/(k + 1) < d_j\n",
    "            # with the intent of inserting k evenly spaced points \n",
    "            # between x_i and x_{i+1}\n",
    "            k = int(max(1, np.ceil(d_i/d_j - 1)))\n",
    "\n",
    "            # Shrink k if necessary so as not to exceed number of remaining points\n",
    "            k = min(k, n)\n",
    "        except ValueError:\n",
    "            # Here xs has only two elements, hence diffs has only one element.\n",
    "            # Using try-except because faster than if-else.\n",
    "            i = 0\n",
    "            d_i = diffs[0]\n",
    "            k = n\n",
    "        \n",
    "        # Insert the k points, updating xs\n",
    "        xs = np.concatenate([\n",
    "          xs[:i + 1], \n",
    "          [xs[i] + s*d_i/(k + 1) for s in range(1, k + 1)], \n",
    "          xs[i + 1:]\n",
    "          ])\n",
    "        \n",
    "        # Update n\n",
    "        n -= k\n",
    "        \n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test refine() some\n",
    "\n",
    "xs = np.array([0, 3/4, 1])\n",
    "assert np.array_equal(refine(xs, 0), xs)\n",
    "assert np.array_equal(refine(xs, 1), np.array([0, 3/8, 3/4, 1]))\n",
    "assert np.array_equal(refine(xs, 2), np.array([0, 1/4, 1/2, 3/4, 1]))\n",
    "assert np.array_equal(refine(xs, 3), np.array([0, 1/4, 1/2, 3/4, 7/8, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_patterns(feed, trip_ids=None, sep='-'):\n",
    "    \"\"\"\n",
    "    Return the DataFrame ``feed.trips`` with the additional column\n",
    "    \n",
    "    - ``'stop_pattern'``: string; the stop IDs along the \n",
    "      trip joined by the separator ``sep``\n",
    "      \n",
    "    If a list of trip IDs is also given, then restrict the output\n",
    "    to those trip IDs.\n",
    "    \"\"\"\n",
    "    st = feed.stop_times.sort_values(['trip_id', 'stop_sequence'])\n",
    "    if trip_ids is not None:\n",
    "        # Filter to given trip IDs\n",
    "        st = st[st['trip_id'].isin(trip_ids)].copy()\n",
    "            \n",
    "    def get_pattern(group):\n",
    "        return group.stop_id.str.cat(sep=sep)\n",
    "        \n",
    "    f = st.groupby('trip_id').apply(get_pattern).reset_index().rename(\n",
    "      columns={0: 'stop_pattern'})\n",
    "    return feed.trips.merge(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sample_points_by_trip(feed, trip_ids=None, n=100):\n",
    "    \"\"\"\n",
    "    Given a GTFS feed (GTFSTK Feed instance), \n",
    "    preferably with a ``feed.stop_times.shape_dist_traveled`` column, \n",
    "    return a dictionary of the form \n",
    "    \n",
    "    trip ID -> list of n (longitude, latitude) sample points along trip.\n",
    "    \n",
    "    Regarding the list of sample points, suppose a trip has k stops.\n",
    "    If k < n, the trip has a shape, and all the ``shape_dist_traveled``\n",
    "    values of the trip's stop times are present, then the sample points \n",
    "    comprise the k stops of the trip along with ``n - k`` additional points\n",
    "    somewhat evenly sampled from the trip's shape, all in the order of the trip's travel.\n",
    "    Else if k > n, then the sample points include only n stops: no points (n=0); \n",
    "    the first stop (n=1); the first and the last stop (n=2);\n",
    "    the first, last, and n - k random stops (n > 2).\n",
    "    Else, the sample points are the k stops.\n",
    "    \n",
    "    NOTES:\n",
    "    \n",
    "    - In the case of choosing random stops, the choices will be the same\n",
    "      for across all runs of this function (by using a fixed \n",
    "      random number generator seed), which is good for debugging.\n",
    "    \"\"\"\n",
    "    # Seed random number generator for reproducible results\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    if trip_ids is None:\n",
    "        # Use all trip IDs\n",
    "        trip_ids = feed.trips.trip_id\n",
    "    \n",
    "    # Get stops times\n",
    "    st = feed.stop_times\n",
    "    st = st[st['trip_id'].isin(trip_ids)].sort_values(\n",
    "      ['trip_id', 'stop_sequence'])\n",
    "    \n",
    "    # Join in stop patterns\n",
    "    t = get_stop_patterns(feed, trip_ids)\n",
    "    st = st.merge(t[['trip_id', 'shape_id', 'stop_pattern']])\n",
    "    \n",
    "    # Join in stop locations\n",
    "    st = st.merge(feed.stops[['stop_id', 'stop_lon', 'stop_lat']])\n",
    "\n",
    "    # Create shape_dist_traveled column if it does not exist\n",
    "    if not 'shape_dist_traveled' in st:\n",
    "        st['shape_dist_traveled'] = np.nan\n",
    "    \n",
    "    # Get shape geometries\n",
    "    geom_by_shape = feed.build_geometry_by_shape(shape_ids=t.shape_id) or {}\n",
    "\n",
    "    # First build dictionary (shape ID, stop pattern) -> list of (lon, lat) sample points,\n",
    "    # instead of trip ID -> list of (lon, lat) sample points, because the former\n",
    "    # avoids repeating computations\n",
    "    points_by_ssp = {}    \n",
    "    for trip_id, group in st.groupby('trip_id'):\n",
    "        shape_id, stop_pattern = group[['shape_id', 'stop_pattern']].iloc[0]\n",
    "        if (shape_id, stop_pattern) in points_by_ssp:\n",
    "            # Already computed\n",
    "            continue\n",
    "            \n",
    "        k = group.shape[0]  # Number of stops along trip\n",
    "        if k < n and (shape_id in geom_by_shape)\\\n",
    "          and group['shape_dist_traveled'].notnull().all():\n",
    "            # Start with stop points, and mark their distances for later sorting.\n",
    "            # Scale distances to interval [0, 1] to avoid changing coordinate systems.            \n",
    "            group['shape_dist_traveled'] /= group['shape_dist_traveled'].max()\n",
    "            stop_points = group[['stop_lon', 'stop_lat', 'shape_dist_traveled']].values\n",
    "            dists = group['shape_dist_traveled'].values\n",
    "            \n",
    "            # Get n - k nicely spaced points from trip shape.\n",
    "            new_dists = np.setdiff1d(refine(dists, n - k), dists)                 \n",
    "            geom = geom_by_shape[shape_id]\n",
    "            shape_points = [\n",
    "              list(geom.interpolate(d, normalized=True).coords[0]) + [d]\n",
    "              for d in new_dists]\n",
    "            \n",
    "            # Combine with stop points and sort\n",
    "            points = sorted(np.concatenate([stop_points, shape_points]).tolist(), \n",
    "              key=lambda x: x[2])\n",
    "            \n",
    "            # Remove distance markers\n",
    "            points = [x[:2] for x in points]\n",
    "\n",
    "        elif k > n:\n",
    "            # Use n stop points only\n",
    "            if n == 0:\n",
    "                points = []\n",
    "            elif n == 1:\n",
    "                # First stop\n",
    "                points = group[['stop_lon', 'stop_lat']].iloc[0].values.tolist() \n",
    "            elif n == 2:\n",
    "                # First and last stop\n",
    "                ix = [0, k - 1]\n",
    "                points = group[['stop_lon', 'stop_lat']].iloc[ix].values.tolist() \n",
    "            else:\n",
    "                # First, last, and n - 2 random stops\n",
    "                ix = np.concatenate([[0, k - 1], \n",
    "                  np.random.choice(range(1, k - 1), n - 2, replace=False)])\n",
    "                ix = sorted(ix)\n",
    "                points = group[['stop_lon', 'stop_lat']].iloc[ix].values.tolist()\n",
    "        else:\n",
    "            # Best can do is use the stop points\n",
    "            points = group[['stop_lon', 'stop_lat']].values.tolist()\n",
    "\n",
    "        points_by_ssp[(shape_id, stop_pattern)] = points\n",
    "\n",
    "    # Build final dict trip ID -> list of (lon, lat) sample points\n",
    "    return {t: points_by_ssp[(s, sp)] \n",
    "      for t, s, sp in t[['trip_id', 'shape_id', 'stop_pattern']].values}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 296 ms, sys: 0 ns, total: 296 ms\n",
      "Wall time: 295 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araichev/.virtualenvs/snap_bus_routes/lib/python3.5/site-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.11 s, sys: 4 ms, total: 3.11 s\n",
      "Wall time: 3.11 s\n"
     ]
    }
   ],
   "source": [
    "t = feed.trips.sample(frac=0.01)\n",
    "%time tp1 = build_sample_points_by_trip(feed, t.trip_id, 4)\n",
    "%time tp2 = build_sample_points_by_trip(feed, t.trip_id, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81__1__3342__VLYF__506__506\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"174.77476475600002 -41.311519434 0.11498608799996646 0.08894986799999316\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,-82.534089)\"><polyline fill=\"none\" stroke=\"#66cc99\" stroke-width=\"0.0022997217599993293\" points=\"174.77902350000002,-41.27858839 174.8854921,-41.22753391 174.8846821,-41.30726069 174.87354130000003,-41.22682831\" opacity=\"0.8\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.linestring.LineString at 0x7f53802f0ba8>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tid = t.trip_id.iat[1]\n",
    "print(tid)\n",
    "l1 = sg.LineString(tp1[tid])\n",
    "l2 = sg.LineString(tp2[tid])\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"174.76998150400001 -41.312737386 0.14787079199999198 0.09367537200001408\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,-82.53179939999998)\"><polyline fill=\"none\" stroke=\"#66cc99\" stroke-width=\"0.0029574158399998398\" points=\"174.8846821,-41.30726069 174.8884456,-41.30521742 174.890675,-41.30382974 174.89218019999998,-41.30218372 174.8943834,-41.29989569 174.8954213,-41.2986176 174.89632680000003,-41.29689133 174.8959165,-41.29509667 174.8971435,-41.29210409 174.8980593,-41.29073792 174.90026709999998,-41.28862984 174.901533,-41.28698765 174.90594280000002,-41.28259127 174.90671530000003,-41.28041676 174.9053266,-41.27782769 174.9045477,-41.27567886 174.9079705,-41.27021787999999 174.9069215,-41.26699269 174.9099372,-41.26397032 174.91237560000002,-41.25753473999999 174.90484540000003,-41.25306595 174.9079668,-41.24959152 174.9098872,-41.24586672 174.9090954,-41.24326777 174.9085686,-41.24156514 174.90792240000002,-41.23986448 174.9066669,-41.23772356 174.9044233,-41.23442802999999 174.8933811,-41.23217824999999 174.8891707,-41.23098641 174.89019209999998,-41.22916819999999 174.888743,-41.22856148 174.8854921,-41.22753391 174.88332749999998,-41.22693884 174.88003733,-41.22583014 174.8758619,-41.22453870999999 174.87354130000003,-41.22682831 174.8476904776576,-41.22767727379826 174.82310483757536,-41.241890404919026 174.79837136560988,-41.25615840884866 174.77977090000002,-41.27533423 174.77902350000002,-41.27858839 174.77653723,-41.27990181 174.7761057,-41.281065399999996 174.7757989,-41.28296166 174.77574234,-41.28493518 174.7754582,-41.28801096 174.7766131,-41.29096552 174.77989,-41.29289647 174.7827796,-41.29375246\" opacity=\"0.8\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.linestring.LineString at 0x7f537eb880b8>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
